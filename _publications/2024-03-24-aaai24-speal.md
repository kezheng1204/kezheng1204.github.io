---
title: "SPEAL: Skeletal Prior Embedded Attention Learning for Cross-Source Point Cloud Registration"
collection: publications
category: conferences
permalink: /publication/2024-03-24-aaai24-speal
excerpt: 'In this paper, we propose a novel method termed SPEAL to leverage skeletal representations for effective learning of intrinsic topologies of point clouds, facilitating robust capture of geometric intricacy.'
date: 2024-03-24
venue: 'AAAI-24 Main Track'
paperurl: 'http://kezheng1204.github.io/files/aaai-24-speal/aaai-24-speal.pdf'
citation: 'Xiong, Kezheng, et al. "SPEAL: Skeletal Prior Embedded Attention Learning for Cross-Source Point Cloud Registration." Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 6. 2024.'
---

[[arXiv]](https://arxiv.org/abs/2312.08664)
[[AAAI]](https://ojs.aaai.org/index.php/AAAI/article/view/28446) 
[[Dataset (Baidu Netdisk, Passcode: `1xh4`)]](https://pan.baidu.com/s/1I3OTFh6isIA6V-0Mtn2XSg)

## Abstract
Point cloud registration, a fundamental task in 3D computer vision, has remained largely unexplored in cross-source point clouds and unstructured scenes. The primary challenges arise from noise, outliers, and variations in scale and density. However, neglected geometric natures of point clouds restricts the performance of current methods. In this paper, we propose a novel method termed SPEAL to leverage skeletal representations for effective learning of intrinsic topologies of point clouds, facilitating robust capture of geometric intricacy. Specifically, we design the Skeleton Extraction Module to extract skeleton points and skeletal features in an unsupervised manner, which is inherently robust to noise and density variances. Then, we propose the Skeleton-Aware GeoTransformer to encode high-level skeleton-aware features. It explicitly captures the topological natures and inter-point-cloud skeletal correlations with the noise-robust and density-invariant skeletal representations. Next, we introduce the Correspondence Dual-Sampler to facilitate correspondences by augmenting the correspondence set with skeletal correspondences. Furthermore, we construct a challenging novel large-scale cross-source point cloud dataset named KITTI CrossSource for benchmarking cross-source point cloud registration methods. Extensive quantitative and qualitative experiments are conducted to demonstrate our approach's superiority and robustness on both cross-source and same-source datasets. To the best of our knowledge, our approach is the first to facilitate point cloud registration with skeletal geometric priors.

## Dataset Release

The KITTI CrossSource dataset toolkit is available at [KITTI CrossSource](https://github.com/kezheng1204/KITTI-CrossSource/).
The full-resolution dataset is about 400GB.
A [downsample version](https://pan.baidu.com/s/1I3OTFh6isIA6V-0Mtn2XSg) is provided for quick test (Passcode: `1xh4`). Please refer to the [README](https://github.com/kezheng1204/KITTI-CrossSource/blob/main/README.md) for more details.


## Citation

```bibtex
@inproceedings{xiong2024speal,
  title={SPEAL: Skeletal Prior Embedded Attention Learning for Cross-Source Point Cloud Registration},
  author={Xiong, Kezheng and Zheng, Maoji and Xu, Qingshan and Wen, Chenglu and Shen, Siqi and Wang, Cheng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={6},
  pages={6279--6287},
  year={2024}
}
```